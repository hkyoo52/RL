### 모델 사용 여부
* 모델의 역활 : action에 따라 environment가 어떻게 바뀔지 암
  * 모델이 정확하다면 훨씬 빠르게 학습 가능
  * 그러나 environment의 정확한 model은 알아내기 어려움
* model free RL
  * 모델에 내부적인 작업 X
  * 느리지만 정확
* model based RL
  * 모델에 직접 custumize함 (Ex. cost function을 정의해서 최적의 action 계산)
  * 빠르지만 덜 정확함

### value와 policy 사용 여부
* Value Based
  * value만 학습시키고 가장 value값이 높은 방향으로 정책을 정함
  * 데이터를 더 효율적으로 사용 가능
  * Ex. DQN
* Policy Based
  * policy를 정확히 구한다면 value는 알 필요 없음(value는 policy를 구하기 위한 중간 과정)
  * 원하는 것을 직접 최적화 -> 안정적으로 학습됨
  * Ex. Policy Gradient

![image](https://user-images.githubusercontent.com/63588046/223053088-6986d14b-59d8-4730-8eb2-08685638cf70.png)

